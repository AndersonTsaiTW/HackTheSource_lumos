# ğŸ”— Node.js Integration & Separation Guide

> **Note**: This project is already integrated. This guide explains:
> 1. How to verify the integration is working
> 2. How to separate the ML model into a standalone service if needed

---

## ğŸ“‹ Current Integration Status

### âœ… Already Integrated Components

1. **Node.js Services** (in `src/services/`)
   - `xgboostService.js` - Calls Python API
   - `featureExtractor.js` - Extracts 45 features
   - `analyzer.js` - Hybrid scoring (ML + rules)

2. **Python ML Model** (in `lumos_XGBoost/`)
   - `api_server.py` - Flask API server
   - `scam_detector_model.pkl` - Trained XGBoost model
   - `requirements.txt` - Python dependencies

3. **Configuration**
   - `package.json` - npm scripts for dual-service startup
   - `src/config.js` - XGBoost API URL configuration

---

## ğŸš€ Quick Start (Use Current Integration)

### 1. Complete Setup (First Time Only)

```bash
# Install Node.js dependencies
npm install

# Install Python dependencies
cd lumos_XGBoost
pip install -r requirements.txt
cd ..

# Add to .env file
echo "XGBOOST_API_URL=http://localhost:5000" >> .env
```

### 2. Start Both Services

```bash
# One command to start both Node.js and Python services
npm run start:all
```

This will:
- Start Node.js API on `http://localhost:3000`
- Start Python Flask API on `http://localhost:5000`

### 3. Test the Integration

```bash
# Test Node.js API (should call Python internally)
curl -X POST http://localhost:3000/api/analyze \
  -H "Content-Type: application/json" \
  -d '{"message": "URGENT! Click http://bit.ly/scam to claim prize! Call 0912345678"}'
```

Expected response includes:
```json
{
  "riskScore": 85,
  "mlScore": 90,
  "riskLevel": "red",
  "evidence": [
    "ğŸ¤– ML Model: 90% scam probability (High confidence)",
    ...
  ]
}
```

---

## ğŸ”§ Troubleshooting Current Integration

### Issue: Missing XGBOOST_API_URL

**Symptom**: ML model not being used, only rule-based scoring

**Solution**: Add to `.env`
```env
XGBOOST_API_URL=http://localhost:5000
```

### Issue: Python Dependencies Not Installed

**Symptom**: `ModuleNotFoundError` when starting Python service

**Solution**:
```bash
cd lumos_XGBoost
pip install -r requirements.txt
```

### Issue: Model File Not Found

**Symptom**: `Model not loaded` error

**Solution**: Train the model
```bash
cd lumos_XGBoost
python train_model.py
```

---

## ğŸ“¦ How to Separate ML Model (Optional)

If you want to deploy the ML model as a separate microservice:

### Option 1: Separate to Different Server

#### Step 1: Extract ML Model to Separate Project

```bash
# On your ML server
mkdir scam-detection-ml-service
cd scam-detection-ml-service

# Copy only ML files
cp -r /path/to/HackTheSource_Lumos/lumos_XGBoost/* .

# Install dependencies
pip install -r requirements.txt

# Start service (use production server)
gunicorn -w 4 -b 0.0.0.0:5000 api_server:app
```

#### Step 2: Update Node.js Project

In your Node.js project, update `.env`:
```env
# Point to remote ML service
XGBOOST_API_URL=http://ml-server.yourcompany.com:5000
```

Remove from `package.json` scripts:
```json
{
  "scripts": {
    "start": "node src/index.js",
    "dev": "nodemon src/index.js"
    // Remove: "ml:start" and "start:all"
  }
}
```

Keep these Node.js files (they still need to call remote ML service):
- `src/services/xgboostService.js`
- `src/services/featureExtractor.js`
- `src/utils/analyzer.js`

### Option 2: Dockerize ML Service

#### Create `lumos_XGBoost/Dockerfile`

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

EXPOSE 5000

CMD ["gunicorn", "-w", "4", "-b", "0.0.0.0:5000", "api_server:app"]
```

#### Create `lumos_XGBoost/docker-compose.yml`

```yaml
version: '3.8'

services:
  ml-service:
    build: .
    ports:
      - "5000:5000"
    volumes:
      - ./scam_detector_model.pkl:/app/scam_detector_model.pkl
      - ./feature_columns.json:/app/feature_columns.json
    environment:
      - FLASK_ENV=production
    restart: always
```

#### Run ML Service in Docker

```bash
cd lumos_XGBoost
docker-compose up -d
```

#### Update Node.js Project

```env
# .env
XGBOOST_API_URL=http://localhost:5000
# or for remote: http://ml-container:5000
```

---

## ğŸ—ï¸ Separation Benefits vs Drawbacks

### Keep Integrated (Current Setup)

**Pros:**
- âœ… Simple deployment (one project)
- âœ… Easy local development
- âœ… No network latency between services
- âœ… Easier debugging

**Cons:**
- âŒ Python + Node.js on same server
- âŒ Can't scale ML service independently
- âŒ More complex dependency management

### Separate Services

**Pros:**
- âœ… Independent scaling (scale ML service separately)
- âœ… Independent deployment and updates
- âœ… Better resource management
- âœ… Can reuse ML service for other projects

**Cons:**
- âŒ Network latency between services
- âŒ More complex deployment
- âŒ Need to manage two projects
- âŒ Potential network failures

---

## ğŸ“Š API Endpoints Reference

### 1. Health Check

```http
GET http://localhost:5000/health
```

**Response:**
```json
{
  "status": "healthy",
  "model_loaded": true
}
```

### 2. Single Prediction

```http
POST http://localhost:5000/predict
Content-Type: application/json
```

**Request Body:**
```json
{
  "char_count": 156,
  "word_count": 23,
  "url_count": 1,
  "phone_count": 1,
  "urgency_level": 8,
  "threat_level": 7,
  ... (45 features total)
}
```

**Response:**
```json
{
  "success": true,
  "result": {
    "is_scam": true,
    "scam_probability": 0.8435,
    "normal_probability": 0.1565,
    "confidence": "High",
    "prediction_label": "Scam"
  }
}
```

### 3. Batch Prediction

```http
POST http://localhost:5000/predict/batch
Content-Type: application/json
```

**Request Body:**
```json
{
  "messages": [
    {...features1...},
    {...features2...}
  ]
}
```

**Response:**
```json
{
  "success": true,
  "results": [
    {...result1...},
    {...result2...}
  ],
  "count": 2
}
```

### 4. Model Info

```http
GET http://localhost:5000/model/info
```

**Response:**
```json
{
  "success": true,
  "info": {
    "feature_count": 45,
    "features": ["char_count", "word_count", ...]
  }
}
```

---

## ğŸ’» Usage in Node.js

### Option 1: Use Example Module

```javascript
const { detectScam } = require('./lumos_XGBoost/nodejs_example');

// Prepare message features (45 features)
const features = {
  char_count: 156,
  word_count: 23,
  url_count: 1,
  phone_count: 1,
  urgency_level: 8,
  // ... other features
};

// Predict
const result = await detectScam(features);
console.log('Is scam:', result.result.is_scam);
console.log('Probability:', result.result.scam_probability);
```

### Option 2: Create Your Own Service

```javascript
const axios = require('axios');

class ScamDetectionService {
  constructor(apiUrl = 'http://localhost:5000') {
    this.apiUrl = apiUrl;
  }

  async predict(features) {
    try {
      const response = await axios.post(
        `${this.apiUrl}/predict`,
        features
      );
      return response.data;
    } catch (error) {
      console.error('Prediction failed:', error.message);
      throw error;
    }
  }

  async checkHealth() {
    const response = await axios.get(`${this.apiUrl}/health`);
    return response.data;
  }
}

// Usage
const detector = new ScamDetectionService();
const result = await detector.predict(messageFeatures);
```

---

## ğŸ”§ Required Features (45 Total)

### Text Features (14)
- char_count, word_count, digit_count, digit_ratio
- uppercase_ratio, special_char_count, exclamation_count
- question_count, has_urgent_keywords, suspicious_word_count
- max_word_length, avg_word_length, emoji_count, consecutive_caps

### URL Features (8)
- url_count, has_suspicious_tld, has_ip_address
- has_url_shortener, avg_url_length, has_https
- url_path_depth, subdomain_count

### Phone Features (7)
- phone_count, has_intl_code, is_voip
- is_mobile, is_valid_phone, phone_carrier_known, has_multiple_phones

### AI Features (12)
- urgency_level, threat_level, temptation_level
- impersonation_type, action_requested, grammar_quality
- emotion_triggers, credibility_score
- ai_is_scam, ai_confidence, has_scam_keywords, keyword_count

### Statistical Features (3)
- text_entropy, readability_score, sentence_complexity

### URL Safety (1)
- google_safe_browsing_flagged

---

## ğŸ“Š Response Format

```javascript
{
  is_scam: boolean,              // true if message is classified as scam
  scam_probability: number,      // 0.0 to 1.0
  normal_probability: number,    // 0.0 to 1.0
  confidence: string,            // "Low", "Medium", "High"
  prediction_label: string       // "Scam" or "Normal"
}
```

### Confidence Levels
- **High**: probability > 0.75
- **Medium**: 0.60 <= probability <= 0.75
- **Low**: probability < 0.60

---

## ğŸ› Troubleshooting

### Issue 1: Connection Failed (ECONNREFUSED)
**Solution**: Ensure Python API service is running at port 5000
```bash
python lumos_XGBoost/api_server.py
```

### Issue 2: Model Load Failed
**Solution**: Train the model first
```bash
cd lumos_XGBoost
python train_model.py
```

### Issue 3: Prediction Error (Missing Features)
**Solution**: Ensure all 45 features are provided. Check `feature_columns.json` for required feature names.

### Issue 4: Chinese Text Encoding
**Solution**: Ensure UTF-8 encoding in API requests
```javascript
axios.post(url, data, {
  headers: { 'Content-Type': 'application/json; charset=UTF-8' }
})
```

---

## ğŸ”’ Production Recommendations

1. **Use Process Manager**
   ```bash
   # For Python service
   gunicorn -w 4 -b 0.0.0.0:5000 api_server:app
   
   # For Node.js service
   pm2 start src/index.js
   ```

2. **Add Health Monitoring**
   - Monitor Python API uptime
   - Implement auto-restart on failure
   - Log prediction results

3. **Security**
   - Add API authentication
   - Rate limiting
   - Input validation

4. **Performance**
   - Use connection pooling
   - Cache frequent predictions
   - Batch requests when possible

---

## ğŸ“ Testing

Run the test script:
```bash
node lumos_XGBoost/nodejs_example.js
```

Expected output:
```
==========================================================
ğŸ” Node.js Scam SMS Detection Example
==========================================================

1ï¸âƒ£ Checking service status...
   Service status: { status: 'healthy', model_loaded: true }

2ï¸âƒ£ Getting model information...
   Feature count: 45

3ï¸âƒ£ Testing scam message detection...
   âœ… Prediction: Scam (84.35%)
   Confidence: High
```

---

## ğŸ“ Need Help?

For more information, see:
- Main integration guide: [XGBOOST_INTEGRATION.md](../XGBOOST_INTEGRATION.md)
- Model documentation: [README.md](README.md)
- Open an issue on GitHub for support

åœ¨ä½ çš„ Node å°ˆæ¡ˆä¸­å»ºç«‹å•Ÿå‹•è…³æœ¬:

```javascript
// start-ml-service.js
const { spawn } = require('child_process');
const path = require('path');

const pythonPath = path.join(__dirname, 'ml-model', '.venv', 'Scripts', 'python.exe');
const scriptPath = path.join(__dirname, 'ml-model', 'api_server.py');

const mlService = spawn(pythonPath, [scriptPath]);

mlService.stdout.on('data', (data) => {
  console.log(`[ML Service] ${data}`);
});

mlService.stderr.on('data', (data) => {
  console.error(`[ML Service Error] ${data}`);
});

mlService.on('close', (code) => {
  console.log(`ML Service exited with code ${code}`);
});

console.log('ğŸš€ ML Service starting...');
```

åœ¨ `package.json` ä¸­åŠ å…¥:

```json
{
  "scripts": {
    "start:ml": "node start-ml-service.js",
    "dev": "concurrently \"npm run start:ml\" \"npm run dev:server\""
  }
}
```

---

## ğŸ“¡ API ç«¯é»

### 1. Health Check

```javascript
GET http://localhost:5000/health

Response:
{
  "status": "healthy",
  "model_loaded": true
}
```

### 2. å–®ç­†é æ¸¬

```javascript
POST http://localhost:5000/predict
Content-Type: application/json

Request Body:
{
  // æ–‡æœ¬æ¬„ä½ (å¿…è¦ - æ¨¡å‹ä½¿ç”¨æ–‡æœ¬ç‰¹å¾µ)
  "message_text": "æ‚¨çš„åŒ…è£¹éœ€è¦è£œç¹³é‹è²»...",
  "openai_keywords": "åŒ…è£¹,é‹è²»,é»æ“Š",
  "openai_reason": "è¦æ±‚é»æ“Šå¯ç–‘é€£çµ",
  "openai_emotion_triggers": "ç·Šæ€¥,é€¾æœŸ",
  "openai_action_requested": "click_link",
  "openai_impersonation_type": "courier",
  
  // æ•¸å€¼æ¬„ä½ (33å€‹)
  "message_length": 68,
  "contains_urgent_words": 1,
  "has_url": 1,
  // ... å…¶ä»–æ¬„ä½
}

Response:
{
  "success": true,
  "result": {
    "is_scam": true,
    "scam_probability": 0.8435,
    "normal_probability": 0.1565,
    "confidence": "High",
    "prediction_label": "Scam",
    "top_scam_factors": [
      {
        "feature": "message_length",
        "value": 68.0,
        "importance": 0.014,
        "contribution_score": 0.952
      },
      // ... å‰5å
    ]
  }
}
```

### 3. æ‰¹æ¬¡é æ¸¬

```javascript
POST http://localhost:5000/predict/batch
Content-Type: application/json

Request Body:
{
  "messages": [
    { /* message 1 features */ },
    { /* message 2 features */ }
  ]
}

Response:
{
  "success": true,
  "results": [
    { /* result 1 */ },
    { /* result 2 */ }
  ],
  "count": 2
}
```

### 4. æ¨¡å‹è³‡è¨Š

```javascript
GET http://localhost:5000/model/info

Response:
{
  "success": true,
  "info": {
    "feature_count": 79,
    "features": ["message_length", "tfidf_msg_0", ...]
  }
}
```

---

## ğŸ’» åœ¨ Node.js ä¸­ä½¿ç”¨

### æ–¹å¼ 1: ç›´æ¥ä½¿ç”¨ç¯„ä¾‹æ¨¡çµ„

```javascript
// your-app.js
const scamDetector = require('./ml-model/nodejs_example');

async function checkMessage(messageData) {
  try {
    // å–®ç­†é æ¸¬
    const result = await scamDetector.detectScam(messageData);
    
    console.log('Is scam:', result.result.is_scam);
    console.log('Probability:', result.result.scam_probability);
    console.log('Top factors:', result.result.top_scam_factors);
    
    return result.result;
  } catch (error) {
    console.error('Detection failed:', error);
    throw error;
  }
}
```

### æ–¹å¼ 2: å»ºç«‹è‡ªå·±çš„æœå‹™é¡åˆ¥

```javascript
// services/ScamDetectionService.js
const axios = require('axios');

class ScamDetectionService {
  constructor(apiUrl = 'http://localhost:5000') {
    this.apiUrl = apiUrl;
  }

  async predict(messageData) {
    try {
      const response = await axios.post(`${this.apiUrl}/predict`, messageData);
      return response.data.result;
    } catch (error) {
      console.error('Scam detection error:', error.message);
      throw error;
    }
  }

  async predictBatch(messages) {
    try {
      const response = await axios.post(`${this.apiUrl}/predict/batch`, {
        messages
      });
      return response.data.results;
    } catch (error) {
      console.error('Batch prediction error:', error.message);
      throw error;
    }
  }

  async isHealthy() {
    try {
      const response = await axios.get(`${this.apiUrl}/health`);
      return response.data.model_loaded;
    } catch (error) {
      return false;
    }
  }
}

module.exports = ScamDetectionService;
```

ä½¿ç”¨ç¯„ä¾‹:

```javascript
const ScamDetectionService = require('./services/ScamDetectionService');
const detector = new ScamDetectionService();

// åœ¨ä½ çš„ route æˆ– controller ä¸­
app.post('/api/check-sms', async (req, res) => {
  try {
    const { message_text, ...otherFeatures } = req.body;
    
    // ç¢ºä¿æœå‹™å¥åº·
    if (!await detector.isHealthy()) {
      return res.status(503).json({ 
        error: 'ML service unavailable' 
      });
    }
    
    // é æ¸¬
    const result = await detector.predict({
      message_text,
      ...otherFeatures
    });
    
    res.json({
      success: true,
      prediction: result
    });
  } catch (error) {
    res.status(500).json({ 
      error: error.message 
    });
  }
});
```

---

## ğŸ”§ å¿…è¦æ¬„ä½èªªæ˜

### æ–‡æœ¬æ¬„ä½ (Text Features)
- `message_text`: ç°¡è¨Šå…§å®¹ (å¿…è¦)
- `openai_keywords`: OpenAI æå–çš„é—œéµå­—
- `openai_reason`: åˆ¤æ–·åŸå› 
- `openai_emotion_triggers`: æƒ…ç·’è§¸ç™¼è©
- `openai_action_requested`: è¦æ±‚çš„è¡Œå‹• (click_link, reply, call_number, provide_info)
- `openai_impersonation_type`: å†’å……é¡å‹ (company, bank, government, courier)

### æ•¸å€¼æ¬„ä½ (Numeric Features) - 33å€‹
- `message_length`: è¨Šæ¯é•·åº¦
- `contains_urgent_words`: æ˜¯å¦åŒ…å«ç·Šæ€¥è©å½™ (0/1)
- `contains_money_keywords`: æ˜¯å¦åŒ…å«é‡‘éŒ¢é—œéµå­— (0/1)
- `has_url`: æ˜¯å¦æœ‰ç¶²å€ (0/1)
- `url_is_shortened`: æ˜¯å¦ç‚ºçŸ­ç¶²å€ (0/1)
- `openai_is_scam`: OpenAI åˆ¤æ–·æ˜¯å¦è©é¨™ (0/1)
- `openai_confidence`: OpenAI ä¿¡å¿ƒåˆ†æ•¸ (0-100)
- `openai_urgency_level`: ç·Šæ€¥ç¨‹åº¦ (0-10)
- `openai_threat_level`: å¨è„…ç¨‹åº¦ (0-10)
- `openai_credibility_score`: å¯ä¿¡åº¦åˆ†æ•¸ (0-10)
- ... ç­‰ (å…±33å€‹)

å®Œæ•´æ¬„ä½åˆ—è¡¨è«‹åƒè€ƒ `feature_columns.json`

---

## ğŸ“Š å›å‚³çµæœèªªæ˜

```javascript
{
  is_scam: boolean,              // æ˜¯å¦ç‚ºè©é¨™
  scam_probability: number,      // è©é¨™æ©Ÿç‡ (0-1)
  normal_probability: number,    // æ­£å¸¸æ©Ÿç‡ (0-1)
  confidence: string,            // ä¿¡å¿ƒæ°´æº–: "High" / "Medium" / "Low"
  prediction_label: string,      // é æ¸¬æ¨™ç±¤: "Scam" / "Normal"
  top_scam_factors: [            // å‰5å¤§æ”¯æŒè©é¨™çš„ç‰¹å¾µ
    {
      feature: string,           // ç‰¹å¾µåç¨±
      value: number,             // ç‰¹å¾µå€¼
      importance: number,        // æ¨¡å‹ä¸­çš„é‡è¦æ€§
      contribution_score: number // è²¢ç»åˆ†æ•¸ = importance Ã— value
    }
  ]
}
```

### ä¿¡å¿ƒæ°´æº–åˆ¤å®š
- **High**: è©é¨™æ©Ÿç‡ â‰¥ 80%
- **Medium**: è©é¨™æ©Ÿç‡ 60-80%
- **Low**: è©é¨™æ©Ÿç‡ < 60%

---

## ğŸ› é™¤éŒ¯æç¤º

### å•é¡Œ 1: é€£ç·šå¤±æ•— (ECONNREFUSED)
```
è§£æ±ºæ–¹æ³•: ç¢ºèª Python API æœå‹™å·²å•Ÿå‹•
python api_server.py
```

### å•é¡Œ 2: æ¨¡å‹è¼‰å…¥å¤±æ•—
```
è§£æ±ºæ–¹æ³•: 
1. ç¢ºèª scam_detector_model.pkl å­˜åœ¨
2. æª¢æŸ¥ Python ä¾è³´æ˜¯å¦å®Œæ•´å®‰è£
   pip install -r requirements.txt
```

### å•é¡Œ 3: é æ¸¬éŒ¯èª¤ (ç¼ºå°‘ç‰¹å¾µ)
```
è§£æ±ºæ–¹æ³•: ç¢ºä¿æä¾›æ‰€æœ‰å¿…è¦æ¬„ä½
- æ–‡æœ¬æ¬„ä½: message_text (å¿…è¦)
- è‡³å°‘æä¾›åŸºæœ¬æ•¸å€¼æ¬„ä½ï¼Œç¼ºå°‘çš„æœƒè‡ªå‹•å¡« 0
```

### å•é¡Œ 4: ä¸­æ–‡äº‚ç¢¼
```
è§£æ±ºæ–¹æ³•: ç¢ºä¿ API è«‹æ±‚ä½¿ç”¨ UTF-8 ç·¨ç¢¼
axios.defaults.headers.post['Content-Type'] = 'application/json;charset=UTF-8';
```

---

## ğŸ”’ ç”Ÿç”¢ç’°å¢ƒå»ºè­°

1. **ä½¿ç”¨ PM2 ç®¡ç† Python æœå‹™**
   ```bash
   npm install -g pm2
   pm2 start api_server.py --interpreter python
   ```

2. **åŠ å…¥éŒ¯èª¤é‡è©¦æ©Ÿåˆ¶**
   ```javascript
   const axiosRetry = require('axios-retry');
   axiosRetry(axios, { retries: 3 });
   ```

3. **è¨­å®š timeout**
   ```javascript
   axios.post(url, data, { timeout: 5000 });
   ```

4. **åŠ å…¥å¿«å–æ©Ÿåˆ¶** (é‡å°ç›¸åŒè¨Šæ¯)
   ```javascript
   const cache = new Map();
   // æª¢æŸ¥ cache å†å‘¼å« API
   ```

5. **ä½¿ç”¨ç’°å¢ƒè®Šæ•¸ç®¡ç† URL**
   ```javascript
   const ML_API_URL = process.env.ML_API_URL || 'http://localhost:5000';
   ```

---

## ğŸ“ æ¸¬è©¦

åŸ·è¡Œç¯„ä¾‹æ¸¬è©¦:

```bash
# 1. å•Ÿå‹• API æœå‹™
cd ml-model
python api_server.py

# 2. åœ¨å¦ä¸€å€‹çµ‚ç«¯åŸ·è¡Œ Node.js æ¸¬è©¦
node ml-model/nodejs_example.js
```

ä½ æ‡‰è©²æœƒçœ‹åˆ°å®Œæ•´çš„æ¸¬è©¦çµæœ,åŒ…æ‹¬é æ¸¬çµæœå’Œå‰äº”å¤§å› å­ã€‚

---

## ğŸ“ éœ€è¦å¹«åŠ©?

- æª¢æŸ¥ `model_metrics.json` æŸ¥çœ‹æ¨¡å‹æ•ˆèƒ½
- æª¢æŸ¥ `feature_importance.png` æŸ¥çœ‹ç‰¹å¾µé‡è¦æ€§
- åƒè€ƒ `nodejs_example.js` å®Œæ•´ç¯„ä¾‹ä»£ç¢¼
